2-create_ids.py:
    input: 1-output.txt - raw Boa query output from get_comment_changes.boa
    output: 2-id_output.txt - assigned a unique dataset ID to all rows from get_comment_changes.boa for joins + recovery later on

3-preprocess.py:
    input: 2-id_output.txt
    output: 3-preprocessed.txt - all comment changes whose texts are less than 2 characters are removed
    
4-prepare_cc.py:
    input: 3-preprocessed.txt
    output: 4-prepared_cc.txt - prepares data for classification by previous work's comment classifier by removing all data except the ID and text
    
6-keyword_search.py:
    input: 3-preprocessed.txt
    output: 6-keyword_output.txt - all comments which contain an SATD-indicating keyword as found by previous work
    
7-union.py:
    input: 2-id_output.txt, 6-keyword_output.txt, 5-cc_output.txt (comments classified as SATD by previous work) 
    output: 7-union.txt - all data joined by IDs which are in either 6-keyword.txt or 5-cc_output.txt
    
8-regex.py:
    input: 7-union.txt
    output: 8-autogen_removed_sorted.txt - comments which are likely autogenerated have been removed (e.g: "NOQA")
    
9-get_link.py:
    input: 8-autogen_removed_sorted.txt
    output: 9-link_output.txt - combining comment introducing with commits that remove a comment with the same repo, file, and text

10-remove_anyduplicated.py:
    input: 9-link_output.txt
    output: 10-removed_duplication.txt - removing any non-unique commits (repo, file, and text are the same)
    
11-clean_dataset.py:
    input: 10-removed_duplication.txt
    output: 11-cleaned.txt - reorganize the dataset column orderings
    
12-remove-sitepackages.py:
    input: 11-cleaned.txt
    output: 12-sitepackages_removed.txt - removes all comments which appeared in a "site-packages" folder
    
13-split_tool_app.py:
    input: 12-sitepackages_removed
    output: 13-apps.csv, 13-tools.csv - our dataset split on whether a repo appeared in a tool or application repository
    